# Data Description
The project is experimental in nature. The main goal of the data is to record physical measurements of the system over the course of several minutes at each operating condition, with operating conditions being chosen and adjusted to derive a trend in temperature, flow, or some other key characteristic. The data can be divided into two groups, determined by the acquisition device.
Labview Data
The majority of the sensors transmit electrical signals to a National Instruments Data Aquisition System, a device capable of transmitting these signals to a computer. A program called Labview allows the user to decide how these signals are received, read, adjusted, and recorded. These readings are processed and recorded in a CSV file, which is later processed through a tool like Matlab to generate metadata and summaries. The key measurements are purposes are as follows:
Temperature: Several temperature sensors throughout the loop measure the fluid temperature. This is used to estimate the heat transfer performance, as well as diagnose sources of error, like an uninsulated section loosing heat.
Pressure: A single point pressure transducer reports back the static pressure of the fluid at this point. This reading is used to look up thermal properties, like the expected density. A differential pressure sensor will compare the pressure at two points, helping to estimate how well a fluid flows across a section of interest, usually a heated portion.
Flow and Density: A coriolis meter measures the fluidâ€™s flow rate and density. These factors are used to compare the fluid to other cases and act as a verification of pressure and temperature sensors.
Power: Power is the representation of how much heat is entering the system, which is the key factor in determining thermal performance. The power supply has no senor associated with it, and thus the output is manually entered by the user into the Labview script, which will in turn record it into the output CSV file.
Fiberoptic Data
A fiberoptic cable is a novel way of measuring temperature across multiple points. By threading it through a heated piece of the system, like a tube, it will report the temperature at nearly twenty locations along its length and at a high frequency. This is used in tandem with the temperature of the fluid, the power entering the system as heat, and the flow rate to determine the heat transfer performance. However this data must be processed through a separate device to get a CSV file, which then must be run through a Matlab (or similar) program to produce anything meaningful. As such, the code used to process it must be clearly documented, have a revision history, and be available with the published data. Additionally, the data can by quite expansive, so metadata summaries are encouraged.
Each recording of a statepoint will produce two CSV files; one from the Labview readout and one of the fiberoptic data. These files are quite small and are thus expected to produce at most one gigabyte of data within the scope of this data. The fiberoptic data is often processed and saved as a 2D when combined with the labview data, which will produce up to another gigabyte of metadata.
# Roles and responsibilities
PI: access control, DMP implementation, protection of sensitive and protected data, quality control
Due to their experience and manager role, the PI (advising professor) will primarily act to ensure that the data is handled responsibly. This will include determining who has access to unpublished data, protecting data under NDA, and ensuring the quality and authenticity of any data published. In the event of a student leaving the project, all roles will fall to the PI until they find a suitable replacement.
Grad Student 1: data manager, instrumentation maintenance, data collection/data generation, data organization, metadata generation; quality control, data analysis
The graduate student, as the more experienced student working on the project, will be responsible for the majority of data processing, analysis, and visualization. Data presented to the graduate student by the undergraduate should be checked for quality before being processed and sensor calibration will be done by the graduate student.
Undergraduate: data collection, data organization
The undergraduate student will be the main data collector. Simple organization tasks, like file naming and placement in corresponding folders will be their responsibility as well.
# Data standards and metadata
# Storage and security
Box
Any and all data not under NDA will be stored in an OSU-managed Box Drive. This will ensure all interested parties have access to synchronized data. The PI will control access to data storage. Metadata generated for the purpose of visualization, along with materials related to publication should also be stored in the Box Drive.
ScholarsArchive@OSU
Raw data and metadata relevant to publication will be published through the OSU data repository ScholarsArchive@OSU. This will be done to allow open access in the future without management from the PI.
# Access and data sharing
# Archiving and preservation
To ensure access to data is maintained before and after publication a data redundancy plan will be implemented. This plan will primarily rely upon mirroring all data stored in a cloud to a physical format. A dedicated external hard drive will be synced to the drive automatically on a daily basis through the Box program tools. Students are encouraged to enable this for their own devices to create multiple copies and to speed up access. The Box Drive is licensed and managed by OSU and thus should persist after publication and departure of students or the PI. Any data under NDA should only be held long enough to process for further analysis, and thus does not need to be reproduced. In the event of NDA data loss similar files should be archived and the set of data relating to what is lost shall be reproduced.
